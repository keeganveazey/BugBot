{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9eb3a90-0f71-4138-a1c2-e2912520172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0, VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a78ec38e-3e00-4309-a0e5-92ee31b260d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a4f9517-f274-4d94-8768-10c4254e657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3080 Ti Laptop GPU, compute capability 8.6\n",
      "Found 6642 images belonging to 11 classes.\n",
      "Found 440 images belonging to 11 classes.\n",
      "Found 220 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# Enable Mixed Precision for Faster Training\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "# Define Constants\n",
    "TRAIN_DIR = \"PROCESSED_DATA/TRAINING_DATA/TRAINING_AUGMENTED_DATA\"\n",
    "VALID_DIR = \"PROCESSED_DATA/VALIDATION_DATA/\"\n",
    "TEST_DIR = \"PROCESSED_DATA/TEST_DATA/\"\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NORMALIZE_FLAG = True\n",
    "\n",
    "# Data Generators\n",
    "NORM_DATAGEN = ImageDataGenerator(rescale=1./255)\n",
    "NO_FRILLS_DATAGEN = ImageDataGenerator()\n",
    "\n",
    "# Data Loading Function\n",
    "def load_data(directory, shuffle_flag=True):\n",
    "    generator = NORM_DATAGEN.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=shuffle_flag\n",
    "    ) if NORMALIZE_FLAG else NO_FRILLS_DATAGEN.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=shuffle_flag\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "# Load Data\n",
    "TRAIN_GENERATOR = load_data(TRAIN_DIR)\n",
    "VAL_GENERATOR = load_data(VALID_DIR)\n",
    "TEST_GENERATOR = load_data(TEST_DIR, shuffle_flag=False)\n",
    "\n",
    "hp = HyperParameters()\n",
    "\n",
    "# Model Building Function\n",
    "def build_tunable_cnn(hp):\n",
    "    model = Sequential([\n",
    "        Input(shape=(224, 224, 3)),\n",
    "        Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(hp.Float(\"dropout\", min_value=0.2, max_value=0.5, step=0.1)), \n",
    "        Dense(TRAIN_GENERATOR.num_classes, activation='softmax', dtype='float32')\n",
    "    ])\n",
    "    \n",
    "    learning_rate = hp.Choice('lr', values=[1e-2, 1e-3, 1e-4])\n",
    "    batch_size = hp.Choice('batch_size', values=[16, 32])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Hyperparameter Tuning Function\n",
    "def build_best_model():\n",
    "    tuner = kt.BayesianOptimization(\n",
    "        build_tunable_cnn,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=20,\n",
    "        executions_per_trial=1,\n",
    "        directory='bayesian_tuning',\n",
    "        project_name='lr_and_drop_tuning'\n",
    "    )\n",
    "    \n",
    "    tuner.search(TRAIN_GENERATOR, validation_data=VAL_GENERATOR, epochs=10)\n",
    "    \n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_hps_dict = {\n",
    "        'best_lr': best_hps.get('lr'),\n",
    "        'best_dropout': best_hps.get('dropout'),\n",
    "        'best_batch_size': best_hps.get('batch_size')\n",
    "    }\n",
    "    \n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "    best_model_training_history = best_model.fit(\n",
    "        TRAIN_GENERATOR, \n",
    "        validation_data=VAL_GENERATOR, \n",
    "        epochs=10, \n",
    "        batch_size=best_hps.get('batch_size')\n",
    "    )\n",
    "\n",
    "    return best_hps_dict, best_model, best_model_training_history\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, filename=\"best_model.h5\"):\n",
    "    test_loss, test_acc = model.evaluate(TEST_GENERATOR)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    model.save(filename)\n",
    "    print(f\"Model saved as {filename}\")\n",
    "\n",
    "    return test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84ed19dc-6a12-4664-9fad-62c6052fe24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 01m 32s]\n",
      "val_accuracy: 0.46590909361839294\n",
      "\n",
      "Best val_accuracy So Far: 0.4749999940395355\n",
      "Total elapsed time: 00h 32m 11s\n",
      "Epoch 1/10\n",
      "208/208 [==============================] - 10s 42ms/step - loss: 2.2924 - accuracy: 0.1721 - val_loss: 2.1886 - val_accuracy: 0.2409\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 9s 41ms/step - loss: 2.0362 - accuracy: 0.3022 - val_loss: 2.0563 - val_accuracy: 0.3159\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 8s 40ms/step - loss: 1.7908 - accuracy: 0.3978 - val_loss: 1.9219 - val_accuracy: 0.3795\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 8s 39ms/step - loss: 1.5927 - accuracy: 0.4714 - val_loss: 1.8795 - val_accuracy: 0.3818\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 8s 39ms/step - loss: 1.3965 - accuracy: 0.5388 - val_loss: 1.8880 - val_accuracy: 0.4318\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 8s 40ms/step - loss: 1.2094 - accuracy: 0.6072 - val_loss: 1.9581 - val_accuracy: 0.4477\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 9s 41ms/step - loss: 1.0389 - accuracy: 0.6694 - val_loss: 1.9243 - val_accuracy: 0.4500\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 8s 39ms/step - loss: 0.8964 - accuracy: 0.7177 - val_loss: 1.9755 - val_accuracy: 0.4500\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 8s 40ms/step - loss: 0.7636 - accuracy: 0.7590 - val_loss: 2.1570 - val_accuracy: 0.4523\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 8s 40ms/step - loss: 0.6512 - accuracy: 0.7967 - val_loss: 2.1776 - val_accuracy: 0.4523\n",
      "Best Hyperparameters:\n",
      " {'best_lr': 0.0001, 'best_dropout': 0.2, 'best_batch_size': 32}\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 2.3778 - accuracy: 0.3727\n",
      "Test Accuracy: 0.3727\n",
      "Model saved as best_model.h5\n",
      "Test Loss: 2.377784252166748, Test Accuracy: 0.37272727489471436\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Main Training Function\n",
    "def main():\n",
    "\n",
    "    with tf.device('/GPU:0'):  # Forces execution on GPU 0\n",
    "        best_hps_dict, best_model, best_model_training_history = build_best_model()\n",
    "        print(f'Best Hyperparameters:\\n {best_hps_dict}')\n",
    "        \n",
    "        test_loss, test_acc = evaluate_model(best_model)\n",
    "        print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n",
    "        \n",
    "        best_model.save(\"simple_cnn_best_model_bayes_optimization.h5\")\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "# Run Training\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f87a83-cc2a-4bd7-a6af-09029cabb373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39cee9-d91c-4c6d-b314-80c71bf9edba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8b781-7c01-4808-a2ec-8b4f85e92944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
